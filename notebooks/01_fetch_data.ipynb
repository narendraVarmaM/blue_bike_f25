{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d224c917",
   "metadata": {},
   "source": [
    "# Fetching DATA\n",
    "\n",
    "### 1. Bike rides data  \n",
    "\n",
    "Files are downloaded extracted and csvs are picked and data id extracted and stored in .parquet files\n",
    "\n",
    "\n",
    "Parquet stores data column by column, allowing analytical queries to read only the required columns, drastically improving speed and reducing I/O compared to row-based CSVs. \n",
    "\n",
    "\n",
    "Its columnar format enables more effective compression, leading to much smaller file sizes and lower storage costs. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07f40f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2aa674ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_raw_trip_data(year: int, month: int) -> str:\n",
    "    base_url = \"https://s3.amazonaws.com/hubway-data\"\n",
    "    patterns = [\n",
    "        f\"{year}{month:02}-bluebikes-tripdata.csv.zip\",\n",
    "        f\"{year}{month:02}-bluebikes-tripdata.zip\",\n",
    "    ]\n",
    "\n",
    "    raw_dir = Path(\"..\") / \"data\" / \"raw\"\n",
    "    raw_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 1) Download ZIP\n",
    "    zip_path = None\n",
    "    for fname in patterns:\n",
    "        url = f\"{base_url}/{fname}\"\n",
    "        resp = requests.get(url, stream=True)\n",
    "        if resp.status_code == 200:\n",
    "            zip_path = raw_dir / fname\n",
    "            with open(zip_path, \"wb\") as f:\n",
    "                for chunk in resp.iter_content(8_192):\n",
    "                    f.write(chunk)\n",
    "            print(f\"Downloaded {url}\")\n",
    "            break\n",
    "        else:\n",
    "            print(f\"{url} returned {resp.status_code}\")\n",
    "    if not zip_path:\n",
    "        raise FileNotFoundError(f\"No CSV ZIP found for {year}-{month:02}\")\n",
    "\n",
    "    # 2) Extract CSV(s)\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as z:\n",
    "        z.extractall(raw_dir)\n",
    "    print(f\"Extracted to {raw_dir}\")\n",
    "\n",
    "    # 3) Collect CSV files\n",
    "    csvs = list(raw_dir.glob(f\"{year}{month:02}*-bluebikes-tripdata*.csv\"))\n",
    "    if not csvs:\n",
    "        csvs = list(raw_dir.glob(\"*.csv\"))\n",
    "    folder = raw_dir / zip_path.stem\n",
    "    if folder.is_dir():\n",
    "        csvs += list(folder.glob(\"*.csv\"))\n",
    "\n",
    "    if not csvs:\n",
    "        raise FileNotFoundError(f\"No CSVs found after extracting {zip_path}\")\n",
    "\n",
    "    # 4) Read & concatenate\n",
    "    dfs = []\n",
    "    for csv in csvs:\n",
    "        print(f\"Reading {csv.relative_to(raw_dir)}\")\n",
    "        dfs.append(pd.read_csv(csv))\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    print(f\"DataFrame shape: {df.shape}\")\n",
    "    # 5) Clean & convert to Parquet\n",
    "\n",
    "    df.dropna(subset=[\"start_station_id\", \"end_station_id\"], inplace=True)\n",
    "    \n",
    "    print(f\"DataFrame shape after cleaning: {df.shape}\")\n",
    "\n",
    "    out_path = raw_dir / f\"rides_{year}_{month:02}.parquet\"\n",
    "    df.to_parquet(out_path, index=False)\n",
    "    print(f\"Converted to parquet: {out_path}\")\n",
    "\n",
    "    \n",
    "    try:\n",
    "        zip_path.unlink()\n",
    "        for csv in csvs:\n",
    "            csv.unlink()\n",
    "        print(\"Cleaned up ZIP and CSV files\")\n",
    "    except Exception as e:\n",
    "        print(f\"Cleanup warning: {e}\")\n",
    "\n",
    "    return str(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a476f16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://s3.amazonaws.com/hubway-data/202304-bluebikes-tripdata.csv.zip returned 404\n",
      "Downloaded https://s3.amazonaws.com/hubway-data/202304-bluebikes-tripdata.zip\n",
      "Extracted to ../data/raw\n",
      "Reading 202304-bluebikes-tripdata.csv\n",
      "DataFrame shape: (296291, 13)\n",
      "DataFrame shape after cleaning: (294553, 13)\n",
      "Converted to parquet: ../data/raw/rides_2023_04.parquet\n",
      "Cleaned up ZIP and CSV files\n",
      "https://s3.amazonaws.com/hubway-data/202305-bluebikes-tripdata.csv.zip returned 404\n",
      "Downloaded https://s3.amazonaws.com/hubway-data/202305-bluebikes-tripdata.zip\n",
      "Extracted to ../data/raw\n",
      "Reading 202305-bluebikes-tripdata.csv\n",
      "DataFrame shape: (387593, 13)\n",
      "DataFrame shape after cleaning: (385574, 13)\n",
      "Converted to parquet: ../data/raw/rides_2023_05.parquet\n",
      "Cleaned up ZIP and CSV files\n",
      "https://s3.amazonaws.com/hubway-data/202306-bluebikes-tripdata.csv.zip returned 404\n",
      "Downloaded https://s3.amazonaws.com/hubway-data/202306-bluebikes-tripdata.zip\n",
      "Extracted to ../data/raw\n",
      "Reading 202306-bluebikes-tripdata.csv\n",
      "DataFrame shape: (367839, 13)\n",
      "DataFrame shape after cleaning: (365730, 13)\n",
      "Converted to parquet: ../data/raw/rides_2023_06.parquet\n",
      "Cleaned up ZIP and CSV files\n",
      "https://s3.amazonaws.com/hubway-data/202307-bluebikes-tripdata.csv.zip returned 404\n",
      "Downloaded https://s3.amazonaws.com/hubway-data/202307-bluebikes-tripdata.zip\n",
      "Extracted to ../data/raw\n",
      "Reading 202307-bluebikes-tripdata.csv\n",
      "DataFrame shape: (411509, 13)\n",
      "DataFrame shape after cleaning: (408852, 13)\n",
      "Converted to parquet: ../data/raw/rides_2023_07.parquet\n",
      "Cleaned up ZIP and CSV files\n",
      "https://s3.amazonaws.com/hubway-data/202308-bluebikes-tripdata.csv.zip returned 404\n",
      "Downloaded https://s3.amazonaws.com/hubway-data/202308-bluebikes-tripdata.zip\n",
      "Extracted to ../data/raw\n",
      "Reading 202308-bluebikes-tripdata.csv\n",
      "DataFrame shape: (441706, 13)\n",
      "DataFrame shape after cleaning: (439438, 13)\n",
      "Converted to parquet: ../data/raw/rides_2023_08.parquet\n",
      "Cleaned up ZIP and CSV files\n",
      "https://s3.amazonaws.com/hubway-data/202309-bluebikes-tripdata.csv.zip returned 404\n",
      "Downloaded https://s3.amazonaws.com/hubway-data/202309-bluebikes-tripdata.zip\n",
      "Extracted to ../data/raw\n",
      "Reading 202309-bluebikes-tripdata.csv\n",
      "DataFrame shape: (419874, 13)\n",
      "DataFrame shape after cleaning: (417690, 13)\n",
      "Converted to parquet: ../data/raw/rides_2023_09.parquet\n",
      "Cleaned up ZIP and CSV files\n",
      "https://s3.amazonaws.com/hubway-data/202310-bluebikes-tripdata.csv.zip returned 404\n",
      "Downloaded https://s3.amazonaws.com/hubway-data/202310-bluebikes-tripdata.zip\n",
      "Extracted to ../data/raw\n",
      "Reading 202310-bluebikes-tripdata.csv\n",
      "DataFrame shape: (435867, 13)\n",
      "DataFrame shape after cleaning: (433442, 13)\n",
      "Converted to parquet: ../data/raw/rides_2023_10.parquet\n",
      "Cleaned up ZIP and CSV files\n",
      "https://s3.amazonaws.com/hubway-data/202311-bluebikes-tripdata.csv.zip returned 404\n",
      "Downloaded https://s3.amazonaws.com/hubway-data/202311-bluebikes-tripdata.zip\n",
      "Extracted to ../data/raw\n",
      "Reading 202311-bluebikes-tripdata.csv\n",
      "DataFrame shape: (270816, 13)\n",
      "DataFrame shape after cleaning: (269494, 13)\n",
      "Converted to parquet: ../data/raw/rides_2023_11.parquet\n",
      "Cleaned up ZIP and CSV files\n",
      "https://s3.amazonaws.com/hubway-data/202312-bluebikes-tripdata.csv.zip returned 404\n",
      "Downloaded https://s3.amazonaws.com/hubway-data/202312-bluebikes-tripdata.zip\n",
      "Extracted to ../data/raw\n",
      "Reading 202312-bluebikes-tripdata.csv\n",
      "DataFrame shape: (169380, 13)\n",
      "DataFrame shape after cleaning: (168854, 13)\n",
      "Converted to parquet: ../data/raw/rides_2023_12.parquet\n",
      "Cleaned up ZIP and CSV files\n"
     ]
    }
   ],
   "source": [
    "for month in range(4, 13):\n",
    "    try:\n",
    "        fetch_raw_trip_data(2023, month)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {2023}-{month:02}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f6ff35b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://s3.amazonaws.com/hubway-data/202401-bluebikes-tripdata.csv.zip returned 404\n",
      "Downloaded https://s3.amazonaws.com/hubway-data/202401-bluebikes-tripdata.zip\n",
      "Extracted to ../data/raw\n",
      "Reading 202401-bluebikes-tripdata.csv\n",
      "DataFrame shape: (166699, 13)\n",
      "DataFrame shape after cleaning: (166200, 13)\n",
      "Converted to parquet: ../data/raw/rides_2024_01.parquet\n",
      "Cleaned up ZIP and CSV files\n",
      "https://s3.amazonaws.com/hubway-data/202402-bluebikes-tripdata.csv.zip returned 404\n",
      "Downloaded https://s3.amazonaws.com/hubway-data/202402-bluebikes-tripdata.zip\n",
      "Extracted to ../data/raw\n",
      "Reading 202402-bluebikes-tripdata.csv\n",
      "DataFrame shape: (231947, 13)\n",
      "DataFrame shape after cleaning: (231163, 13)\n",
      "Converted to parquet: ../data/raw/rides_2024_02.parquet\n",
      "Cleaned up ZIP and CSV files\n",
      "https://s3.amazonaws.com/hubway-data/202403-bluebikes-tripdata.csv.zip returned 404\n",
      "Downloaded https://s3.amazonaws.com/hubway-data/202403-bluebikes-tripdata.zip\n",
      "Extracted to ../data/raw\n",
      "Reading 202403-bluebikes-tripdata.csv\n",
      "DataFrame shape: (261687, 13)\n",
      "DataFrame shape after cleaning: (261187, 13)\n",
      "Converted to parquet: ../data/raw/rides_2024_03.parquet\n",
      "Cleaned up ZIP and CSV files\n",
      "https://s3.amazonaws.com/hubway-data/202404-bluebikes-tripdata.csv.zip returned 404\n",
      "Downloaded https://s3.amazonaws.com/hubway-data/202404-bluebikes-tripdata.zip\n",
      "Extracted to ../data/raw\n",
      "Reading 202404-bluebikes-tripdata.csv\n",
      "DataFrame shape: (356327, 13)\n",
      "DataFrame shape after cleaning: (355732, 13)\n",
      "Converted to parquet: ../data/raw/rides_2024_04.parquet\n",
      "Cleaned up ZIP and CSV files\n",
      "https://s3.amazonaws.com/hubway-data/202405-bluebikes-tripdata.csv.zip returned 404\n",
      "Downloaded https://s3.amazonaws.com/hubway-data/202405-bluebikes-tripdata.zip\n",
      "Extracted to ../data/raw\n",
      "Reading 202405-bluebikes-tripdata.csv\n",
      "DataFrame shape: (440534, 13)\n",
      "DataFrame shape after cleaning: (439836, 13)\n",
      "Converted to parquet: ../data/raw/rides_2024_05.parquet\n",
      "Cleaned up ZIP and CSV files\n",
      "https://s3.amazonaws.com/hubway-data/202406-bluebikes-tripdata.csv.zip returned 404\n",
      "Downloaded https://s3.amazonaws.com/hubway-data/202406-bluebikes-tripdata.zip\n",
      "Extracted to ../data/raw\n",
      "Reading 202406-bluebikes-tripdata.csv\n",
      "DataFrame shape: (478860, 13)\n",
      "DataFrame shape after cleaning: (477935, 13)\n",
      "Converted to parquet: ../data/raw/rides_2024_06.parquet\n",
      "Cleaned up ZIP and CSV files\n",
      "https://s3.amazonaws.com/hubway-data/202407-bluebikes-tripdata.csv.zip returned 404\n",
      "Downloaded https://s3.amazonaws.com/hubway-data/202407-bluebikes-tripdata.zip\n",
      "Extracted to ../data/raw\n",
      "Reading 202407-bluebikes-tripdata.csv\n",
      "DataFrame shape: (542622, 13)\n",
      "DataFrame shape after cleaning: (541530, 13)\n",
      "Converted to parquet: ../data/raw/rides_2024_07.parquet\n",
      "Cleaned up ZIP and CSV files\n",
      "https://s3.amazonaws.com/hubway-data/202408-bluebikes-tripdata.csv.zip returned 404\n",
      "Downloaded https://s3.amazonaws.com/hubway-data/202408-bluebikes-tripdata.zip\n",
      "Extracted to ../data/raw\n",
      "Reading 202408-bluebikes-tripdata.csv\n",
      "DataFrame shape: (538262, 13)\n",
      "DataFrame shape after cleaning: (537094, 13)\n",
      "Converted to parquet: ../data/raw/rides_2024_08.parquet\n",
      "Cleaned up ZIP and CSV files\n",
      "https://s3.amazonaws.com/hubway-data/202409-bluebikes-tripdata.csv.zip returned 404\n",
      "Downloaded https://s3.amazonaws.com/hubway-data/202409-bluebikes-tripdata.zip\n",
      "Extracted to ../data/raw\n",
      "Reading 202409-bluebikes-tripdata.csv\n",
      "DataFrame shape: (582679, 13)\n",
      "DataFrame shape after cleaning: (581624, 13)\n",
      "Converted to parquet: ../data/raw/rides_2024_09.parquet\n",
      "Cleaned up ZIP and CSV files\n",
      "https://s3.amazonaws.com/hubway-data/202410-bluebikes-tripdata.csv.zip returned 404\n",
      "Downloaded https://s3.amazonaws.com/hubway-data/202410-bluebikes-tripdata.zip\n",
      "Extracted to ../data/raw\n",
      "Reading 202410-bluebikes-tripdata.csv\n",
      "DataFrame shape: (564156, 13)\n",
      "DataFrame shape after cleaning: (563198, 13)\n",
      "Converted to parquet: ../data/raw/rides_2024_10.parquet\n",
      "Cleaned up ZIP and CSV files\n",
      "https://s3.amazonaws.com/hubway-data/202411-bluebikes-tripdata.csv.zip returned 404\n",
      "Downloaded https://s3.amazonaws.com/hubway-data/202411-bluebikes-tripdata.zip\n",
      "Extracted to ../data/raw\n",
      "Reading 202411-bluebikes-tripdata.csv\n",
      "DataFrame shape: (397406, 13)\n",
      "DataFrame shape after cleaning: (396705, 13)\n",
      "Converted to parquet: ../data/raw/rides_2024_11.parquet\n",
      "Cleaned up ZIP and CSV files\n",
      "https://s3.amazonaws.com/hubway-data/202412-bluebikes-tripdata.csv.zip returned 404\n",
      "Downloaded https://s3.amazonaws.com/hubway-data/202412-bluebikes-tripdata.zip\n",
      "Extracted to ../data/raw\n",
      "Reading 202412-bluebikes-tripdata.csv\n",
      "DataFrame shape: (190611, 13)\n",
      "DataFrame shape after cleaning: (190042, 13)\n",
      "Converted to parquet: ../data/raw/rides_2024_12.parquet\n",
      "Cleaned up ZIP and CSV files\n"
     ]
    }
   ],
   "source": [
    "for month in range(1, 13):\n",
    "    try:\n",
    "        fetch_raw_trip_data(2024, month)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {2024}-{month:02}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d1ddd49f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://s3.amazonaws.com/hubway-data/202501-bluebikes-tripdata.csv.zip returned 404\n",
      "Downloaded https://s3.amazonaws.com/hubway-data/202501-bluebikes-tripdata.zip\n",
      "Extracted to ../data/raw\n",
      "Reading 202501-bluebikes-tripdata.csv\n",
      "DataFrame shape: (162316, 13)\n",
      "DataFrame shape after cleaning: (161926, 13)\n",
      "Converted to parquet: ../data/raw/rides_2025_01.parquet\n",
      "Cleaned up ZIP and CSV files\n",
      "https://s3.amazonaws.com/hubway-data/202502-bluebikes-tripdata.csv.zip returned 404\n",
      "Downloaded https://s3.amazonaws.com/hubway-data/202502-bluebikes-tripdata.zip\n",
      "Extracted to ../data/raw\n",
      "Reading 202502-bluebikes-tripdata.csv\n",
      "DataFrame shape: (166022, 13)\n",
      "DataFrame shape after cleaning: (165742, 13)\n",
      "Converted to parquet: ../data/raw/rides_2025_02.parquet\n",
      "Cleaned up ZIP and CSV files\n",
      "https://s3.amazonaws.com/hubway-data/202503-bluebikes-tripdata.csv.zip returned 404\n",
      "Downloaded https://s3.amazonaws.com/hubway-data/202503-bluebikes-tripdata.zip\n",
      "Extracted to ../data/raw\n",
      "Reading 202503-bluebikes-tripdata.csv\n",
      "DataFrame shape: (272088, 13)\n",
      "DataFrame shape after cleaning: (271605, 13)\n",
      "Converted to parquet: ../data/raw/rides_2025_03.parquet\n",
      "Cleaned up ZIP and CSV files\n",
      "https://s3.amazonaws.com/hubway-data/202504-bluebikes-tripdata.csv.zip returned 404\n",
      "Downloaded https://s3.amazonaws.com/hubway-data/202504-bluebikes-tripdata.zip\n",
      "Extracted to ../data/raw\n",
      "Reading 202504-bluebikes-tripdata.csv\n",
      "DataFrame shape: (373940, 13)\n",
      "DataFrame shape after cleaning: (373257, 13)\n",
      "Converted to parquet: ../data/raw/rides_2025_04.parquet\n",
      "Cleaned up ZIP and CSV files\n",
      "https://s3.amazonaws.com/hubway-data/202505-bluebikes-tripdata.csv.zip returned 404\n",
      "Downloaded https://s3.amazonaws.com/hubway-data/202505-bluebikes-tripdata.zip\n",
      "Extracted to ../data/raw\n",
      "Reading 202505-bluebikes-tripdata.csv\n",
      "DataFrame shape: (429840, 13)\n",
      "DataFrame shape after cleaning: (429077, 13)\n",
      "Converted to parquet: ../data/raw/rides_2025_05.parquet\n",
      "Cleaned up ZIP and CSV files\n",
      "https://s3.amazonaws.com/hubway-data/202506-bluebikes-tripdata.csv.zip returned 404\n",
      "Downloaded https://s3.amazonaws.com/hubway-data/202506-bluebikes-tripdata.zip\n",
      "Extracted to ../data/raw\n",
      "Reading 202506-bluebikes-tripdata.csv\n",
      "DataFrame shape: (488202, 13)\n",
      "DataFrame shape after cleaning: (487146, 13)\n",
      "Converted to parquet: ../data/raw/rides_2025_06.parquet\n",
      "Cleaned up ZIP and CSV files\n",
      "https://s3.amazonaws.com/hubway-data/202507-bluebikes-tripdata.csv.zip returned 404\n",
      "Downloaded https://s3.amazonaws.com/hubway-data/202507-bluebikes-tripdata.zip\n",
      "Extracted to ../data/raw\n",
      "Reading 202507-bluebikes-tripdata.csv\n",
      "DataFrame shape: (539711, 13)\n",
      "DataFrame shape after cleaning: (538372, 13)\n",
      "Converted to parquet: ../data/raw/rides_2025_07.parquet\n",
      "Cleaned up ZIP and CSV files\n",
      "https://s3.amazonaws.com/hubway-data/202508-bluebikes-tripdata.csv.zip returned 404\n",
      "Downloaded https://s3.amazonaws.com/hubway-data/202508-bluebikes-tripdata.zip\n",
      "Extracted to ../data/raw\n",
      "Reading 202508-bluebikes-tripdata.csv\n",
      "DataFrame shape: (549014, 13)\n",
      "DataFrame shape after cleaning: (547835, 13)\n",
      "Converted to parquet: ../data/raw/rides_2025_08.parquet\n",
      "Cleaned up ZIP and CSV files\n"
     ]
    }
   ],
   "source": [
    "for month in range(1, 9):\n",
    "    try:\n",
    "        fetch_raw_trip_data(2025, month)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {2025}-{month:02}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8cadee05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://s3.amazonaws.com/hubway-data/202509-bluebikes-tripdata.csv.zip returned 404\n",
      "Downloaded https://s3.amazonaws.com/hubway-data/202509-bluebikes-tripdata.zip\n",
      "Extracted to ../data/raw\n",
      "Reading 202509-bluebikes-tripdata.csv\n",
      "DataFrame shape: (586979, 13)\n",
      "DataFrame shape after cleaning: (585931, 13)\n",
      "Converted to parquet: ../data/raw/rides_2025_09.parquet\n",
      "Cleaned up ZIP and CSV files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../data/raw/rides_2025_09.parquet'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch_raw_trip_data(2025, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e50b7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e113045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43a08272",
   "metadata": {},
   "outputs": [],
   "source": [
    "STATIONS_FILE = \"/mnt/data/-External-_Bluebikes_Station_List.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6b37a74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>NAME</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>Seasonal Status</th>\n",
       "      <th>Municipality</th>\n",
       "      <th>Total Docks</th>\n",
       "      <th>Station ID (to match to historic system data)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L32001</td>\n",
       "      <td>Railroad Lot and Minuteman Bikeway</td>\n",
       "      <td>42.416065</td>\n",
       "      <td>-71.153366</td>\n",
       "      <td>Year Round</td>\n",
       "      <td>Arlington</td>\n",
       "      <td>11</td>\n",
       "      <td>461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L32002</td>\n",
       "      <td>Linwood St at Minuteman Bikeway</td>\n",
       "      <td>42.409354</td>\n",
       "      <td>-71.149065</td>\n",
       "      <td>Year Round</td>\n",
       "      <td>Arlington</td>\n",
       "      <td>11</td>\n",
       "      <td>462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L32005</td>\n",
       "      <td>Thorndike Field at Minuteman Bikeway</td>\n",
       "      <td>42.400168</td>\n",
       "      <td>-71.144570</td>\n",
       "      <td>Year Round</td>\n",
       "      <td>Arlington</td>\n",
       "      <td>11</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L32003</td>\n",
       "      <td>Mass Ave at Grafton St</td>\n",
       "      <td>42.407261</td>\n",
       "      <td>-71.143821</td>\n",
       "      <td>Year Round</td>\n",
       "      <td>Arlington</td>\n",
       "      <td>11</td>\n",
       "      <td>464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L32004</td>\n",
       "      <td>Broadway at Grafton St</td>\n",
       "      <td>42.409942</td>\n",
       "      <td>-71.140093</td>\n",
       "      <td>Winter Storage</td>\n",
       "      <td>Arlington</td>\n",
       "      <td>11</td>\n",
       "      <td>465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number                                  NAME        Lat       Long  \\\n",
       "0  L32001    Railroad Lot and Minuteman Bikeway  42.416065 -71.153366   \n",
       "1  L32002       Linwood St at Minuteman Bikeway  42.409354 -71.149065   \n",
       "2  L32005  Thorndike Field at Minuteman Bikeway  42.400168 -71.144570   \n",
       "3  L32003                Mass Ave at Grafton St  42.407261 -71.143821   \n",
       "4  L32004                Broadway at Grafton St  42.409942 -71.140093   \n",
       "\n",
       "  Seasonal Status Municipality  Total Docks  \\\n",
       "0      Year Round    Arlington           11   \n",
       "1      Year Round    Arlington           11   \n",
       "2      Year Round    Arlington           11   \n",
       "3      Year Round    Arlington           11   \n",
       "4  Winter Storage    Arlington           11   \n",
       "\n",
       "  Station ID (to match to historic system data)  \n",
       "0                                           461  \n",
       "1                                           462  \n",
       "2                                           480  \n",
       "3                                           464  \n",
       "4                                           465  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "\n",
    "\n",
    "API_KEY = \"ceb8408f78806b389b91c54f68c364f6\"   # <-- insert your key here\n",
    "BASE_URL = \"https://history.openweathermap.org/data/2.5/history/city\"\n",
    "\n",
    "STATIONS_FILE = \"/Users/narendravarma/Documents/blue_bikes/data/raw/-External-_Bluebikes_Station_List.xlsx\"\n",
    "OUTPUT_FILE = \"bluebikes_with_weather_2023.parquet\"\n",
    "\n",
    "# ================================\n",
    "# WEATHER FETCH FUNCTION\n",
    "# ================================\n",
    "def fetch_openweather_history(lat: float, lon: float, start: datetime, end: datetime, units: str = \"metric\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fetch hourly historical weather from OpenWeather for the given lat/lon and time window.\n",
    "    Breaks into small chunks (5 days) due to API limits.\n",
    "    \"\"\"\n",
    "    all_records = []\n",
    "    window = timedelta(days=5)\n",
    "    current_start = start\n",
    "\n",
    "    while current_start < end:\n",
    "        current_end = min(current_start + window, end)\n",
    "        start_unix = int(current_start.timestamp())\n",
    "        end_unix = int(current_end.timestamp())\n",
    "\n",
    "        params = {\n",
    "            \"lat\": lat,\n",
    "            \"lon\": lon,\n",
    "            \"type\": \"hour\",\n",
    "            \"start\": start_unix,\n",
    "            \"end\": end_unix,\n",
    "            \"units\": units,\n",
    "            \"appid\": API_KEY,\n",
    "        }\n",
    "\n",
    "        resp = requests.get(BASE_URL, params=params)\n",
    "        if resp.status_code != 200:\n",
    "            print(f\"Error {resp.status_code} for {lat},{lon} from {current_start} to {current_end}\")\n",
    "        else:\n",
    "            data = resp.json()\n",
    "            if \"list\" in data:\n",
    "                for entry in data[\"list\"]:\n",
    "                    rec = {\n",
    "                        \"timestamp\": datetime.fromtimestamp(entry[\"dt\"]),\n",
    "                        \"lat_round\": round(lat, 2),\n",
    "                        \"lon_round\": round(lon, 2),\n",
    "                        \"temp\": entry[\"main\"].get(\"temp\"),\n",
    "                        \"humidity\": entry[\"main\"].get(\"humidity\"),\n",
    "                        \"pressure\": entry[\"main\"].get(\"pressure\"),\n",
    "                        \"wind_speed\": entry.get(\"wind\", {}).get(\"speed\"),\n",
    "                        \"wind_deg\": entry.get(\"wind\", {}).get(\"deg\"),\n",
    "                        \"precipitation\": entry.get(\"rain\", {}).get(\"1h\", 0.0)\n",
    "                    }\n",
    "                    all_records.append(rec)\n",
    "\n",
    "        current_start = current_end + timedelta(seconds=1)\n",
    "        time.sleep(1)  # avoid hitting rate limits\n",
    "\n",
    "    return pd.DataFrame(all_records)\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 1. Load Stations\n",
    "# ================================\n",
    "stations = pd.read_excel(STATIONS_FILE, header=1)\n",
    "stations.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "46081e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>NAME</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>Seasonal Status</th>\n",
       "      <th>Municipality</th>\n",
       "      <th>Total Docks</th>\n",
       "      <th>Station ID (to match to historic system data)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L32001</td>\n",
       "      <td>Railroad Lot and Minuteman Bikeway</td>\n",
       "      <td>42.416065</td>\n",
       "      <td>-71.153366</td>\n",
       "      <td>Year Round</td>\n",
       "      <td>Arlington</td>\n",
       "      <td>11</td>\n",
       "      <td>461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L32002</td>\n",
       "      <td>Linwood St at Minuteman Bikeway</td>\n",
       "      <td>42.409354</td>\n",
       "      <td>-71.149065</td>\n",
       "      <td>Year Round</td>\n",
       "      <td>Arlington</td>\n",
       "      <td>11</td>\n",
       "      <td>462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L32005</td>\n",
       "      <td>Thorndike Field at Minuteman Bikeway</td>\n",
       "      <td>42.400168</td>\n",
       "      <td>-71.144570</td>\n",
       "      <td>Year Round</td>\n",
       "      <td>Arlington</td>\n",
       "      <td>11</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L32003</td>\n",
       "      <td>Mass Ave at Grafton St</td>\n",
       "      <td>42.407261</td>\n",
       "      <td>-71.143821</td>\n",
       "      <td>Year Round</td>\n",
       "      <td>Arlington</td>\n",
       "      <td>11</td>\n",
       "      <td>464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L32004</td>\n",
       "      <td>Broadway at Grafton St</td>\n",
       "      <td>42.409942</td>\n",
       "      <td>-71.140093</td>\n",
       "      <td>Winter Storage</td>\n",
       "      <td>Arlington</td>\n",
       "      <td>11</td>\n",
       "      <td>465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number                                  NAME        Lat       Long  \\\n",
       "0  L32001    Railroad Lot and Minuteman Bikeway  42.416065 -71.153366   \n",
       "1  L32002       Linwood St at Minuteman Bikeway  42.409354 -71.149065   \n",
       "2  L32005  Thorndike Field at Minuteman Bikeway  42.400168 -71.144570   \n",
       "3  L32003                Mass Ave at Grafton St  42.407261 -71.143821   \n",
       "4  L32004                Broadway at Grafton St  42.409942 -71.140093   \n",
       "\n",
       "  Seasonal Status Municipality  Total Docks  \\\n",
       "0      Year Round    Arlington           11   \n",
       "1      Year Round    Arlington           11   \n",
       "2      Year Round    Arlington           11   \n",
       "3      Year Round    Arlington           11   \n",
       "4  Winter Storage    Arlington           11   \n",
       "\n",
       "  Station ID (to match to historic system data)  \n",
       "0                                           461  \n",
       "1                                           462  \n",
       "2                                           480  \n",
       "3                                           464  \n",
       "4                                           465  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations = pd.read_excel(STATIONS_FILE, header=1)\n",
    "stations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3abc6887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(572, 10)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c497fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Number                                  NAME        Lat       Long  \\\n",
      "0  L32001    Railroad Lot and Minuteman Bikeway  42.416065 -71.153366   \n",
      "1  L32002       Linwood St at Minuteman Bikeway  42.409354 -71.149065   \n",
      "2  L32005  Thorndike Field at Minuteman Bikeway  42.400168 -71.144570   \n",
      "3  L32003                Mass Ave at Grafton St  42.407261 -71.143821   \n",
      "4  L32004                Broadway at Grafton St  42.409942 -71.140093   \n",
      "\n",
      "  Seasonal Status Municipality  Total Docks  \\\n",
      "0      Year Round    Arlington           11   \n",
      "1      Year Round    Arlington           11   \n",
      "2      Year Round    Arlington           11   \n",
      "3      Year Round    Arlington           11   \n",
      "4  Winter Storage    Arlington           11   \n",
      "\n",
      "  Station ID (to match to historic system data)  lat_round  lon_round  \n",
      "0                                           461       42.4      -71.2  \n",
      "1                                           462       42.4      -71.1  \n",
      "2                                           480       42.4      -71.1  \n",
      "3                                           464       42.4      -71.1  \n",
      "4                                           465       42.4      -71.1  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((7, 2),\n",
       "     lat_round  lon_round\n",
       " 0        42.4      -71.2\n",
       " 1        42.4      -71.1\n",
       " 6        42.4      -71.0\n",
       " 10       42.3      -71.1\n",
       " 51       42.3      -71.0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations[\"lat_round\"] = stations[\"Lat\"].round(1)\n",
    "stations[\"lon_round\"] = stations[\"Long\"].round(1)\n",
    "\n",
    "print(stations.head())\n",
    "unique_coords = stations[[\"lat_round\", \"lon_round\"]].drop_duplicates()\n",
    "\n",
    "unique_coords.shape, unique_coords.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "34e95410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat_round</th>\n",
       "      <th>lon_round</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42.4</td>\n",
       "      <td>-71.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42.4</td>\n",
       "      <td>-71.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>42.4</td>\n",
       "      <td>-71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>42.3</td>\n",
       "      <td>-71.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>42.3</td>\n",
       "      <td>-71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>42.3</td>\n",
       "      <td>-71.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>42.5</td>\n",
       "      <td>-70.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lat_round  lon_round\n",
       "0         42.4      -71.2\n",
       "1         42.4      -71.1\n",
       "6         42.4      -71.0\n",
       "10        42.3      -71.1\n",
       "51        42.3      -71.0\n",
       "67        42.3      -71.2\n",
       "423       42.5      -70.9"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d63b101a",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_coords = unique_coords.drop(unique_coords.index[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b90b8be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat_round</th>\n",
       "      <th>lon_round</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42.4</td>\n",
       "      <td>-71.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42.4</td>\n",
       "      <td>-71.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>42.4</td>\n",
       "      <td>-71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>42.3</td>\n",
       "      <td>-71.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>42.3</td>\n",
       "      <td>-71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>42.3</td>\n",
       "      <td>-71.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>42.5</td>\n",
       "      <td>-70.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lat_round  lon_round\n",
       "0         42.4      -71.2\n",
       "1         42.4      -71.1\n",
       "6         42.4      -71.0\n",
       "10        42.3      -71.1\n",
       "51        42.3      -71.0\n",
       "67        42.3      -71.2\n",
       "423       42.5      -70.9"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4bf731cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting folium\n",
      "  Downloading folium-0.20.0-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting branca>=0.6.0 (from folium)\n",
      "  Using cached branca-0.8.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: jinja2>=2.9 in /opt/anaconda3/envs/py313/lib/python3.13/site-packages (from folium) (3.1.6)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/py313/lib/python3.13/site-packages (from folium) (2.2.4)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/py313/lib/python3.13/site-packages (from folium) (2.32.3)\n",
      "Collecting xyzservices (from folium)\n",
      "  Downloading xyzservices-2025.4.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/py313/lib/python3.13/site-packages (from jinja2>=2.9->folium) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/py313/lib/python3.13/site-packages (from requests->folium) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/py313/lib/python3.13/site-packages (from requests->folium) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/py313/lib/python3.13/site-packages (from requests->folium) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/py313/lib/python3.13/site-packages (from requests->folium) (2025.1.31)\n",
      "Downloading folium-0.20.0-py2.py3-none-any.whl (113 kB)\n",
      "Using cached branca-0.8.1-py3-none-any.whl (26 kB)\n",
      "Downloading xyzservices-2025.4.0-py3-none-any.whl (90 kB)\n",
      "Installing collected packages: xyzservices, branca, folium\n",
      "Successfully installed branca-0.8.1 folium-0.20.0 xyzservices-2025.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bf609a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map saved to rounded_stations_map.html\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import folium\n",
    "\n",
    "# 1. Create a DataFrame from your coordinates\n",
    "# Note: I'm converting the output you provided into a structured list of unique points\n",
    "data = {\n",
    "    'lat_round': [42.4, 42.4, 42.4, 42.3, 42.3, 42.3, 42.5],\n",
    "    'lon_round': [-71.2, -71.1, -71.0, -71.1, -71.0, -71.2]\n",
    "}\n",
    "df = pd.DataFrame(data).drop_duplicates()\n",
    "\n",
    "# 2. Determine the center point of your data (for initial map view)\n",
    "center_lat = df['lat_round'].mean()\n",
    "center_lon = df['lon_round'].mean()\n",
    "\n",
    "# 3. Initialize the Folium Map\n",
    "# The location (42.4, -71.1) is the center of your data cluster (Boston area)\n",
    "m = folium.Map(location=[center_lat, center_lon], zoom_start=11)\n",
    "\n",
    "# 4. Add a Marker for each unique rounded coordinate\n",
    "for index, row in df.iterrows():\n",
    "    # You can customize the marker with a popup label\n",
    "    popup_text = f\"Lat: {row['lat_round']}, Lon: {row['lon_round']}\"\n",
    "    \n",
    "    folium.Marker(\n",
    "        location=[row['lat_round'], row['lon_round']],\n",
    "        popup=popup_text,\n",
    "        tooltip='Station Cluster'\n",
    "    ).add_to(m)\n",
    "\n",
    "# 5. Save the map to an HTML file\n",
    "# You can open this file in any web browser to view the interactive map\n",
    "m.save('rounded_stations_map.html')\n",
    "\n",
    "print(\"Map saved to rounded_stations_map.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0849dfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dir = Path(\"..\") / \"data\" / \"raw\"\n",
    "raw_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccddfb0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching weather for 42.4,-71.2\n",
      "            timestamp  lat_round  lon_round   temp  humidity  pressure  \\\n",
      "0 2025-01-01 00:00:00       42.4      -71.2  40.82        85      1006   \n",
      "1 2025-01-01 01:00:00       42.4      -71.2  42.57        83      1003   \n",
      "2 2025-01-01 02:00:00       42.4      -71.2  43.59        85      1003   \n",
      "3 2025-01-01 03:00:00       42.4      -71.2  44.11        88      1002   \n",
      "4 2025-01-01 04:00:00       42.4      -71.2  44.53        88      1000   \n",
      "\n",
      "   wind_speed  wind_deg  precipitation  \n",
      "0        6.91        80           0.00  \n",
      "1        8.05        50           0.00  \n",
      "2       11.01       134           5.15  \n",
      "3       14.97        70           5.91  \n",
      "4       19.57        90           0.00  \n",
      "Fetching weather for 42.4,-71.1\n",
      "            timestamp  lat_round  lon_round   temp  humidity  pressure  \\\n",
      "0 2025-01-01 00:00:00       42.4      -71.1  41.04        86      1006   \n",
      "1 2025-01-01 01:00:00       42.4      -71.1  43.03        84      1003   \n",
      "2 2025-01-01 02:00:00       42.4      -71.1  43.90        87      1003   \n",
      "3 2025-01-01 03:00:00       42.4      -71.1  44.38        88      1002   \n",
      "4 2025-01-01 04:00:00       42.4      -71.1  44.69        89      1000   \n",
      "\n",
      "   wind_speed  wind_deg  precipitation  \n",
      "0        6.91        80           0.00  \n",
      "1       13.80        70           0.00  \n",
      "2       14.97        90           2.74  \n",
      "3       14.97        70           8.58  \n",
      "4       12.66        90           0.00  \n",
      "Fetching weather for 42.4,-71.0\n",
      "            timestamp  lat_round  lon_round   temp  humidity  pressure  \\\n",
      "0 2025-01-01 00:00:00       42.4      -71.0  41.56        87      1006   \n",
      "1 2025-01-01 01:00:00       42.4      -71.0  43.41        85      1004   \n",
      "2 2025-01-01 02:00:00       42.4      -71.0  44.40        87      1003   \n",
      "3 2025-01-01 03:00:00       42.4      -71.0  44.67        89      1002   \n",
      "4 2025-01-01 04:00:00       42.4      -71.0  44.94        89      1000   \n",
      "\n",
      "   wind_speed  wind_deg  precipitation  \n",
      "0        7.00        62           0.00  \n",
      "1       13.80        70           0.00  \n",
      "2       14.97        90           4.10  \n",
      "3       14.97        70           7.13  \n",
      "4       12.66        90           0.00  \n",
      "Fetching weather for 42.3,-71.1\n",
      "            timestamp  lat_round  lon_round   temp  humidity  pressure  \\\n",
      "0 2025-01-01 00:00:00       42.3      -71.1  40.78        88      1006   \n",
      "1 2025-01-01 01:00:00       42.3      -71.1  43.00        85      1003   \n",
      "2 2025-01-01 02:00:00       42.3      -71.1  44.10        89      1003   \n",
      "3 2025-01-01 03:00:00       42.3      -71.1  44.49        90      1002   \n",
      "4 2025-01-01 04:00:00       42.3      -71.1  44.85        91      1000   \n",
      "\n",
      "   wind_speed  wind_deg  precipitation  \n",
      "0       18.99       102           0.00  \n",
      "1       20.00        95           0.00  \n",
      "2       21.99       109           2.19  \n",
      "3       15.99       114          11.53  \n",
      "4       13.00       126           0.00  \n",
      "Fetching weather for 42.3,-71.0\n",
      "            timestamp  lat_round  lon_round   temp  humidity  pressure  \\\n",
      "0 2025-01-01 00:00:00       42.3      -71.0  41.32        91      1006   \n",
      "1 2025-01-01 01:00:00       42.3      -71.0  43.41        90      1004   \n",
      "2 2025-01-01 02:00:00       42.3      -71.0  44.65        92      1003   \n",
      "3 2025-01-01 03:00:00       42.3      -71.0  44.96        93      1002   \n",
      "4 2025-01-01 04:00:00       42.3      -71.0  45.36        94      1000   \n",
      "\n",
      "   wind_speed  wind_deg  precipitation  \n",
      "0        5.01       122           0.00  \n",
      "1        5.01       317           0.00  \n",
      "2        5.01        72           0.55  \n",
      "3       14.97        70           4.60  \n",
      "4       19.57        90           0.00  \n",
      "Fetching weather for 42.3,-71.2\n",
      "            timestamp  lat_round  lon_round   temp  humidity  pressure  \\\n",
      "0 2025-01-01 00:00:00       42.3      -71.2  39.92        88      1006   \n",
      "1 2025-01-01 01:00:00       42.3      -71.2  42.10        85      1003   \n",
      "2 2025-01-01 02:00:00       42.3      -71.2  43.23        89      1003   \n",
      "3 2025-01-01 03:00:00       42.3      -71.2  43.77        90      1001   \n",
      "4 2025-01-01 04:00:00       42.3      -71.2  44.15        91      1000   \n",
      "\n",
      "   wind_speed  wind_deg  precipitation  \n",
      "0        5.01         0           0.00  \n",
      "1        7.00         0           0.00  \n",
      "2        7.00         0           5.22  \n",
      "3        8.05        60          10.60  \n",
      "4        5.99         0           0.15  \n",
      "Fetching weather for 42.5,-70.9\n",
      "            timestamp  lat_round  lon_round   temp  humidity  pressure  \\\n",
      "0 2025-01-01 00:00:00       42.5      -70.9  42.03        91      1007   \n",
      "1 2025-01-01 01:00:00       42.5      -70.9  43.32        91      1004   \n",
      "2 2025-01-01 02:00:00       42.5      -70.9  44.40        89      1004   \n",
      "3 2025-01-01 03:00:00       42.5      -70.9  44.51        93      1002   \n",
      "4 2025-01-01 04:00:00       42.5      -70.9  44.74        94      1001   \n",
      "\n",
      "   wind_speed  wind_deg  precipitation  \n",
      "0        7.00       113           0.00  \n",
      "1       13.80        70           0.00  \n",
      "2       14.97        90           5.33  \n",
      "3       14.97        70           4.21  \n",
      "4       13.80        80           1.55  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ky/sdv_5mx579z213_m20420dyr0000gn/T/ipykernel_4167/4011380480.py:20: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  weather_df[\"hour\"] = weather_df[\"timestamp\"].dt.floor(\"H\")\n"
     ]
    }
   ],
   "source": [
    "weather_frames = []\n",
    "month = 1\n",
    "year = 2025\n",
    "start_date = datetime(2025, 2, 1)\n",
    "end_date = datetime(2025, 2, 31, 23, 59, 59)\n",
    "\n",
    "for _, row in unique_coords.iterrows():\n",
    "    lat, lon = row[\"lat_round\"], row[\"lon_round\"]\n",
    "    print(f\"Fetching weather for {lat},{lon}\")\n",
    "    df_weather = fetch_openweather_history(lat, lon, start_date, end_date, units=\"imperial\")\n",
    "    if not df_weather.empty:\n",
    "        print(df_weather.head())\n",
    "        weather_frames.append(df_weather)\n",
    "\n",
    "\n",
    "weather_df = pd.concat(weather_frames, ignore_index=True)\n",
    "\n",
    "# Ensure datetime types\n",
    "weather_df[\"timestamp\"] = pd.to_datetime(weather_df[\"timestamp\"], errors=\"coerce\", utc=True)\n",
    "weather_df[\"hour\"] = weather_df[\"timestamp\"].dt.floor(\"H\")\n",
    "\n",
    "# Enforce numeric types\n",
    "num_cols = [\"temp\", \"humidity\", \"pressure\", \"wind_speed\", \"wind_deg\", \"precipitation\"]\n",
    "for col in num_cols:\n",
    "    weather_df[col] = pd.to_numeric(weather_df[col], errors=\"coerce\")\n",
    "\n",
    "# Enforce float type for lat/lon\n",
    "weather_df[\"lat_round\"] = weather_df[\"lat_round\"].astype(\"float32\")\n",
    "weather_df[\"lon_round\"] = weather_df[\"lon_round\"].astype(\"float32\")\n",
    "\n",
    "out_path1 = raw_dir / f\"weather_{year}_{month:02}.parquet\"\n",
    "\n",
    "# Save clean parquet\n",
    "weather_df.to_parquet(out_path1, index=False, engine=\"pyarrow\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d151236",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from src.config import RAW_DATA_DIR\n",
    "\n",
    "# Configure paths\n",
    "raw_dir = RAW_DATA_DIR  # Update this path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31c0cf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_weather_month(year, month, unique_coords, units=\"imperial\"):\n",
    "    \"\"\"\n",
    "    Download weather data for all coordinates for a specific month\n",
    "    \n",
    "    Parameters:\n",
    "    - year: int (e.g., 2025)\n",
    "    - month: int (1-12)\n",
    "    - unique_coords: DataFrame with lat_round, lon_round columns\n",
    "    - units: temperature units (\"imperial\" or \"metric\")\n",
    "    \n",
    "    Returns:\n",
    "    - Path to saved file if successful, None otherwise\n",
    "    \"\"\"\n",
    "    # Calculate proper start and end dates for the month\n",
    "    if month == 12:\n",
    "        end_year = year + 1\n",
    "        end_month = 1\n",
    "    else:\n",
    "        end_year = year\n",
    "        end_month = month + 1\n",
    "    \n",
    "    start_date = datetime(year, month, 1)\n",
    "    end_date = datetime(end_year, end_month, 1)\n",
    "    # Subtract 1 second to get last moment of the last day of target month\n",
    "    end_date = end_date - pd.Timedelta(seconds=1)\n",
    "    \n",
    "    weather_frames = []\n",
    "    \n",
    "    print(f\"Downloading weather data for {year}-{month:02d}...\")\n",
    "    print(f\"Date range: {start_date.date()} to {end_date.date()}\")\n",
    "    print(f\"Processing {len(unique_coords)} locations...\")\n",
    "    \n",
    "    for _, row in unique_coords.iterrows():\n",
    "        lat, lon = row[\"lat_round\"], row[\"lon_round\"]\n",
    "        df_weather = fetch_openweather_history(lat, lon, start_date, end_date, units=units)\n",
    "        \n",
    "        if not df_weather.empty:\n",
    "            weather_frames.append(df_weather)\n",
    "    \n",
    "    if not weather_frames:\n",
    "        print(\"  No weather data was fetched!\")\n",
    "        return None\n",
    "    \n",
    "    # Combine and process all data\n",
    "    weather_df = pd.concat(weather_frames, ignore_index=True)\n",
    "    \n",
    "    # Data cleaning\n",
    "    weather_df[\"timestamp\"] = pd.to_datetime(weather_df[\"timestamp\"], errors=\"coerce\", utc=True)\n",
    "    weather_df[\"hour\"] = weather_df[\"timestamp\"].dt.floor(\"H\")\n",
    "    \n",
    "    # Enforce numeric types\n",
    "    num_cols = [\"temp\", \"humidity\", \"pressure\", \"wind_speed\", \"wind_deg\", \"precipitation\"]\n",
    "    for col in num_cols:\n",
    "        weather_df[col] = pd.to_numeric(weather_df[col], errors=\"coerce\")\n",
    "    \n",
    "    # Enforce float type for lat/lon\n",
    "    weather_df[\"lat_round\"] = weather_df[\"lat_round\"].astype(\"float32\")\n",
    "    weather_df[\"lon_round\"] = weather_df[\"lon_round\"].astype(\"float32\")\n",
    "    \n",
    "    # Save file\n",
    "    out_path = raw_dir / f\"weather_{year}_{month:02d}.parquet\"\n",
    "    weather_df.to_parquet(out_path, index=False, engine=\"pyarrow\")\n",
    "    \n",
    "    print(f\" Successfully saved {len(weather_df):,} records to: {out_path}\")\n",
    "    return out_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "437a4c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weather data for 2025-09...\n",
      "Date range: 2025-09-01 to 2025-09-30\n",
      "Processing 7 locations...\n",
      " Successfully saved 5,040 records to: ../data/raw/weather_2025_09.parquet\n",
      " Download completed for 2025-09\n",
      " File: ../data/raw/weather_2025_09.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ky/sdv_5mx579z213_m20420dyr0000gn/T/ipykernel_52719/2525369294.py:49: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  weather_df[\"hour\"] = weather_df[\"timestamp\"].dt.floor(\"H\")\n"
     ]
    }
   ],
   "source": [
    "# CONFIGURATION - Update these values for each download\n",
    "YEAR = 2025\n",
    "MONTH = 9  # February\n",
    "\n",
    "# Download weather data\n",
    "result_path = download_weather_month(\n",
    "    year=YEAR, \n",
    "    month=MONTH, \n",
    "    unique_coords=unique_coords,  # Your coordinates DataFrame\n",
    "    units=\"imperial\"\n",
    ")\n",
    "\n",
    "if result_path:\n",
    "    print(f\" Download completed for {YEAR}-{MONTH:02d}\")\n",
    "    print(f\" File: {result_path}\")\n",
    "else:\n",
    "    print(f\" Download failed for {YEAR}-{MONTH:02d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34fddd39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weather data for 2025-08...\n",
      "Date range: 2025-08-01 to 2025-08-31\n",
      "Processing 7 locations...\n",
      " Successfully saved 5,208 records to: ../data/raw/weather_2025_08.parquet\n",
      " Download completed for 2025-08\n",
      " File: ../data/raw/weather_2025_08.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ky/sdv_5mx579z213_m20420dyr0000gn/T/ipykernel_52719/2525369294.py:49: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  weather_df[\"hour\"] = weather_df[\"timestamp\"].dt.floor(\"H\")\n"
     ]
    }
   ],
   "source": [
    "# CONFIGURATION - Update these values for each download\n",
    "YEAR = 2025\n",
    "MONTH = 8  # February\n",
    "\n",
    "# Download weather data\n",
    "result_path = download_weather_month(\n",
    "    year=YEAR, \n",
    "    month=MONTH, \n",
    "    unique_coords=unique_coords,  # Your coordinates DataFrame\n",
    "    units=\"imperial\"\n",
    ")\n",
    "\n",
    "if result_path:\n",
    "    print(f\" Download completed for {YEAR}-{MONTH:02d}\")\n",
    "    print(f\" File: {result_path}\")\n",
    "else:\n",
    "    print(f\" Download failed for {YEAR}-{MONTH:02d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9789e841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weather data for 2025-07...\n",
      "Date range: 2025-07-01 to 2025-07-31\n",
      "Processing 7 locations...\n",
      " Successfully saved 5,208 records to: ../data/raw/weather_2025_07.parquet\n",
      " Download completed for 2025-07\n",
      " File: ../data/raw/weather_2025_07.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ky/sdv_5mx579z213_m20420dyr0000gn/T/ipykernel_52719/2525369294.py:49: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  weather_df[\"hour\"] = weather_df[\"timestamp\"].dt.floor(\"H\")\n"
     ]
    }
   ],
   "source": [
    "# CONFIGURATION - Update these values for each download\n",
    "YEAR = 2025\n",
    "MONTH = 7  # February\n",
    "\n",
    "# Download weather data\n",
    "result_path = download_weather_month(\n",
    "    year=YEAR, \n",
    "    month=MONTH, \n",
    "    unique_coords=unique_coords,  # Your coordinates DataFrame\n",
    "    units=\"imperial\"\n",
    ")\n",
    "\n",
    "if result_path:\n",
    "    print(f\" Download completed for {YEAR}-{MONTH:02d}\")\n",
    "    print(f\" File: {result_path}\")\n",
    "else:\n",
    "    print(f\" Download failed for {YEAR}-{MONTH:02d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c38bd48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weather data for 2025-06...\n",
      "Date range: 2025-06-01 to 2025-06-30\n",
      "Processing 7 locations...\n",
      " Successfully saved 5,040 records to: ../data/raw/weather_2025_06.parquet\n",
      " Download completed for 2025-06\n",
      " File: ../data/raw/weather_2025_06.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ky/sdv_5mx579z213_m20420dyr0000gn/T/ipykernel_52719/2525369294.py:49: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  weather_df[\"hour\"] = weather_df[\"timestamp\"].dt.floor(\"H\")\n"
     ]
    }
   ],
   "source": [
    "# CONFIGURATION - Update these values for each download\n",
    "YEAR = 2025\n",
    "MONTH = 6  # February\n",
    "\n",
    "# Download weather data\n",
    "result_path = download_weather_month(\n",
    "    year=YEAR, \n",
    "    month=MONTH, \n",
    "    unique_coords=unique_coords,  # Your coordinates DataFrame\n",
    "    units=\"imperial\"\n",
    ")\n",
    "\n",
    "if result_path:\n",
    "    print(f\" Download completed for {YEAR}-{MONTH:02d}\")\n",
    "    print(f\" File: {result_path}\")\n",
    "else:\n",
    "    print(f\" Download failed for {YEAR}-{MONTH:02d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3ae318a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weather data for 2025-05...\n",
      "Date range: 2025-05-01 to 2025-05-31\n",
      "Processing 7 locations...\n",
      " Successfully saved 5,208 records to: ../data/raw/weather_2025_05.parquet\n",
      " Download completed for 2025-05\n",
      " File: ../data/raw/weather_2025_05.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ky/sdv_5mx579z213_m20420dyr0000gn/T/ipykernel_52719/2525369294.py:49: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  weather_df[\"hour\"] = weather_df[\"timestamp\"].dt.floor(\"H\")\n"
     ]
    }
   ],
   "source": [
    "# CONFIGURATION - Update these values for each download\n",
    "YEAR = 2025\n",
    "MONTH = 5  # February\n",
    "\n",
    "# Download weather data\n",
    "result_path = download_weather_month(\n",
    "    year=YEAR, \n",
    "    month=MONTH, \n",
    "    unique_coords=unique_coords,  # Your coordinates DataFrame\n",
    "    units=\"imperial\"\n",
    ")\n",
    "\n",
    "if result_path:\n",
    "    print(f\" Download completed for {YEAR}-{MONTH:02d}\")\n",
    "    print(f\" File: {result_path}\")\n",
    "else:\n",
    "    print(f\" Download failed for {YEAR}-{MONTH:02d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b24b33ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weather data for 2025-04...\n",
      "Date range: 2025-04-01 to 2025-04-30\n",
      "Processing 7 locations...\n",
      " Successfully saved 5,040 records to: ../data/raw/weather_2025_04.parquet\n",
      " Download completed for 2025-04\n",
      " File: ../data/raw/weather_2025_04.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ky/sdv_5mx579z213_m20420dyr0000gn/T/ipykernel_52719/2525369294.py:49: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  weather_df[\"hour\"] = weather_df[\"timestamp\"].dt.floor(\"H\")\n"
     ]
    }
   ],
   "source": [
    "# CONFIGURATION - Update these values for each download\n",
    "YEAR = 2025\n",
    "MONTH = 4  # February\n",
    "\n",
    "# Download weather data\n",
    "result_path = download_weather_month(\n",
    "    year=YEAR, \n",
    "    month=MONTH, \n",
    "    unique_coords=unique_coords,  # Your coordinates DataFrame\n",
    "    units=\"imperial\"\n",
    ")\n",
    "\n",
    "if result_path:\n",
    "    print(f\" Download completed for {YEAR}-{MONTH:02d}\")\n",
    "    print(f\" File: {result_path}\")\n",
    "else:\n",
    "    print(f\" Download failed for {YEAR}-{MONTH:02d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56a67a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weather data for 2025-03...\n",
      "Date range: 2025-03-01 to 2025-03-31\n",
      "Processing 7 locations...\n",
      " Successfully saved 5,187 records to: ../data/raw/weather_2025_03.parquet\n",
      " Download completed for 2025-03\n",
      " File: ../data/raw/weather_2025_03.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ky/sdv_5mx579z213_m20420dyr0000gn/T/ipykernel_52719/2525369294.py:49: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  weather_df[\"hour\"] = weather_df[\"timestamp\"].dt.floor(\"H\")\n"
     ]
    }
   ],
   "source": [
    "# CONFIGURATION - Update these values for each download\n",
    "YEAR = 2025\n",
    "MONTH = 3  # February\n",
    "\n",
    "# Download weather data\n",
    "result_path = download_weather_month(\n",
    "    year=YEAR, \n",
    "    month=MONTH, \n",
    "    unique_coords=unique_coords,  # Your coordinates DataFrame\n",
    "    units=\"imperial\"\n",
    ")\n",
    "\n",
    "if result_path:\n",
    "    print(f\" Download completed for {YEAR}-{MONTH:02d}\")\n",
    "    print(f\" File: {result_path}\")\n",
    "else:\n",
    "    print(f\" Download failed for {YEAR}-{MONTH:02d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a94849f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weather data for 2025-02...\n",
      "Date range: 2025-02-01 to 2025-02-28\n",
      "Processing 7 locations...\n",
      " Successfully saved 4,704 records to: ../data/raw/weather_2025_02.parquet\n",
      " Download completed for 2025-02\n",
      " File: ../data/raw/weather_2025_02.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ky/sdv_5mx579z213_m20420dyr0000gn/T/ipykernel_52719/2525369294.py:49: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  weather_df[\"hour\"] = weather_df[\"timestamp\"].dt.floor(\"H\")\n"
     ]
    }
   ],
   "source": [
    "# CONFIGURATION - Update these values for each download\n",
    "YEAR = 2025\n",
    "MONTH = 2  # February\n",
    "\n",
    "# Download weather data\n",
    "result_path = download_weather_month(\n",
    "    year=YEAR, \n",
    "    month=MONTH, \n",
    "    unique_coords=unique_coords,  # Your coordinates DataFrame\n",
    "    units=\"imperial\"\n",
    ")\n",
    "\n",
    "if result_path:\n",
    "    print(f\" Download completed for {YEAR}-{MONTH:02d}\")\n",
    "    print(f\" File: {result_path}\")\n",
    "else:\n",
    "    print(f\" Download failed for {YEAR}-{MONTH:02d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3cad73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURATION - Update these values for each download\n",
    "YEAR = 2025\n",
    "MONTH = 1  # February\n",
    "\n",
    "# Download weather data\n",
    "result_path = download_weather_month(\n",
    "    year=YEAR, \n",
    "    month=MONTH, \n",
    "    unique_coords=unique_coords,  # Your coordinates DataFrame\n",
    "    units=\"imperial\"\n",
    ")\n",
    "\n",
    "if result_path:\n",
    "    print(f\" Download completed for {YEAR}-{MONTH:02d}\")\n",
    "    print(f\" File: {result_path}\")\n",
    "else:\n",
    "    print(f\" Download failed for {YEAR}-{MONTH:02d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f6afdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURATION - Update these values for each download\n",
    "YEAR = 2024\n",
    "MONTH = 10  # February\n",
    "\n",
    "# Download weather data\n",
    "result_path = download_weather_month(\n",
    "    year=YEAR, \n",
    "    month=MONTH, \n",
    "    unique_coords=unique_coords,  # Your coordinates DataFrame\n",
    "    units=\"imperial\"\n",
    ")\n",
    "\n",
    "if result_path:\n",
    "    print(f\" Download completed for {YEAR}-{MONTH:02d}\")\n",
    "    print(f\" File: {result_path}\")\n",
    "else:\n",
    "    print(f\" Download failed for {YEAR}-{MONTH:02d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d105d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURATION - Update these values for each download\n",
    "YEAR = 2024\n",
    "MONTH = 11  # February\n",
    "\n",
    "# Download weather data\n",
    "result_path = download_weather_month(\n",
    "    year=YEAR, \n",
    "    month=MONTH, \n",
    "    unique_coords=unique_coords,  # Your coordinates DataFrame\n",
    "    units=\"imperial\"\n",
    ")\n",
    "\n",
    "if result_path:\n",
    "    print(f\" Download completed for {YEAR}-{MONTH:02d}\")\n",
    "    print(f\" File: {result_path}\")\n",
    "else:\n",
    "    print(f\" Download failed for {YEAR}-{MONTH:02d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2339bcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURATION - Update these values for each download\n",
    "YEAR = 2024\n",
    "MONTH = 12  # February\n",
    "\n",
    "# Download weather data\n",
    "result_path = download_weather_month(\n",
    "    year=YEAR, \n",
    "    month=MONTH, \n",
    "    unique_coords=unique_coords,  # Your coordinates DataFrame\n",
    "    units=\"imperial\"\n",
    ")\n",
    "\n",
    "if result_path:\n",
    "    print(f\" Download completed for {YEAR}-{MONTH:02d}\")\n",
    "    print(f\" File: {result_path}\")\n",
    "else:\n",
    "    print(f\" Download failed for {YEAR}-{MONTH:02d}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
