{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6aa0279a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "141c9384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rides_t-672</th>\n",
       "      <th>rides_t-671</th>\n",
       "      <th>rides_t-670</th>\n",
       "      <th>rides_t-669</th>\n",
       "      <th>rides_t-668</th>\n",
       "      <th>rides_t-667</th>\n",
       "      <th>rides_t-666</th>\n",
       "      <th>rides_t-665</th>\n",
       "      <th>rides_t-664</th>\n",
       "      <th>rides_t-663</th>\n",
       "      <th>...</th>\n",
       "      <th>temp_t-1</th>\n",
       "      <th>wind_speed_t-3</th>\n",
       "      <th>wind_speed_t-2</th>\n",
       "      <th>wind_speed_t-1</th>\n",
       "      <th>precipitation_t-3</th>\n",
       "      <th>precipitation_t-2</th>\n",
       "      <th>precipitation_t-1</th>\n",
       "      <th>target</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>A32002</td>\n",
       "      <td>2024-10-28 22:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>A32002</td>\n",
       "      <td>2024-10-28 23:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>A32002</td>\n",
       "      <td>2024-10-29 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>A32002</td>\n",
       "      <td>2024-10-29 01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>A32002</td>\n",
       "      <td>2024-10-29 02:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404579</th>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>M32085</td>\n",
       "      <td>2025-09-30 19:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404580</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>M32085</td>\n",
       "      <td>2025-09-30 20:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404581</th>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>M32085</td>\n",
       "      <td>2025-09-30 21:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404582</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>M32085</td>\n",
       "      <td>2025-09-30 22:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404583</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>M32085</td>\n",
       "      <td>2025-09-30 23:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>404584 rows × 684 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        rides_t-672  rides_t-671  rides_t-670  rides_t-669  rides_t-668  \\\n",
       "0               0.0          0.0          0.0          3.0          1.0   \n",
       "1               0.0          0.0          3.0          1.0          0.0   \n",
       "2               0.0          3.0          1.0          0.0          0.0   \n",
       "3               3.0          1.0          0.0          0.0          0.0   \n",
       "4               1.0          0.0          0.0          0.0          3.0   \n",
       "...             ...          ...          ...          ...          ...   \n",
       "404579         16.0          9.0          9.0          3.0          3.0   \n",
       "404580          9.0          9.0          3.0          3.0          0.0   \n",
       "404581          9.0          3.0          3.0          0.0          0.0   \n",
       "404582          3.0          3.0          0.0          0.0          2.0   \n",
       "404583          3.0          0.0          0.0          2.0          0.0   \n",
       "\n",
       "        rides_t-667  rides_t-666  rides_t-665  rides_t-664  rides_t-663  ...  \\\n",
       "0               0.0          0.0          0.0          3.0          6.0  ...   \n",
       "1               0.0          0.0          3.0          6.0          8.0  ...   \n",
       "2               0.0          3.0          6.0          8.0          6.0  ...   \n",
       "3               3.0          6.0          8.0          6.0          8.0  ...   \n",
       "4               6.0          8.0          6.0          8.0          4.0  ...   \n",
       "...             ...          ...          ...          ...          ...  ...   \n",
       "404579          0.0          0.0          2.0          0.0          0.0  ...   \n",
       "404580          0.0          2.0          0.0          0.0          0.0  ...   \n",
       "404581          2.0          0.0          0.0          0.0          1.0  ...   \n",
       "404582          0.0          0.0          0.0          1.0          5.0  ...   \n",
       "404583          0.0          0.0          1.0          5.0         13.0  ...   \n",
       "\n",
       "        temp_t-1  wind_speed_t-3  wind_speed_t-2  wind_speed_t-1  \\\n",
       "0            NaN             NaN             NaN             NaN   \n",
       "1            NaN             NaN             NaN             NaN   \n",
       "2            NaN             NaN             NaN             NaN   \n",
       "3            NaN             NaN             NaN             NaN   \n",
       "4            NaN             NaN             NaN             NaN   \n",
       "...          ...             ...             ...             ...   \n",
       "404579       NaN             NaN             NaN             NaN   \n",
       "404580       NaN             NaN             NaN             NaN   \n",
       "404581       NaN             NaN             NaN             NaN   \n",
       "404582       NaN             NaN             NaN             NaN   \n",
       "404583       NaN             NaN             NaN             NaN   \n",
       "\n",
       "        precipitation_t-3  precipitation_t-2  precipitation_t-1  target  \\\n",
       "0                     NaN                NaN                NaN      13   \n",
       "1                     NaN                NaN                NaN       3   \n",
       "2                     NaN                NaN                NaN       1   \n",
       "3                     NaN                NaN                NaN       1   \n",
       "4                     NaN                NaN                NaN       0   \n",
       "...                   ...                ...                ...     ...   \n",
       "404579                NaN                NaN                NaN      16   \n",
       "404580                NaN                NaN                NaN      11   \n",
       "404581                NaN                NaN                NaN       6   \n",
       "404582                NaN                NaN                NaN       9   \n",
       "404583                NaN                NaN                NaN       3   \n",
       "\n",
       "        start_station_id                hour  \n",
       "0                 A32002 2024-10-28 22:00:00  \n",
       "1                 A32002 2024-10-28 23:00:00  \n",
       "2                 A32002 2024-10-29 00:00:00  \n",
       "3                 A32002 2024-10-29 01:00:00  \n",
       "4                 A32002 2024-10-29 02:00:00  \n",
       "...                  ...                 ...  \n",
       "404579            M32085 2025-09-30 19:00:00  \n",
       "404580            M32085 2025-09-30 20:00:00  \n",
       "404581            M32085 2025-09-30 21:00:00  \n",
       "404582            M32085 2025-09-30 22:00:00  \n",
       "404583            M32085 2025-09-30 23:00:00  \n",
       "\n",
       "[404584 rows x 684 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from src.config import TRANSFORMED_DATA_DIR\n",
    "\n",
    "df = pd.read_parquet(TRANSFORMED_DATA_DIR / \"transformed_features_and_target_top50.parquet\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e1d90a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 404584 entries, 0 to 404583\n",
      "Series name: hour\n",
      "Non-Null Count   Dtype         \n",
      "--------------   -----         \n",
      "404584 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1)\n",
      "memory usage: 3.1 MB\n"
     ]
    }
   ],
   "source": [
    "df[\"hour\"].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55522157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(294163, 683)\n",
      "(294163,)\n",
      "(110421, 683)\n",
      "(110421,)\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from src.data_utils import split_time_series_data\n",
    "\n",
    "X_train, y_train, X_test, y_test = split_time_series_data(\n",
    "    df,\n",
    "    cutoff_date=datetime(2025, 7, 1, 0, 0, 0),\n",
    "    target_column=\"target\"\n",
    ")\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5cdf077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_rides_last_4_weeks(X: pd.DataFrame) -> pd.DataFrame:\n",
    "    last_4_weeks_columns = [\n",
    "            f\"rides_t-{7*6}\",  # 1 week ago\n",
    "            f\"rides_t-{14*6}\", # 2 weeks ago\n",
    "            f\"rides_t-{21*6}\", # 3 weeks ago\n",
    "            f\"rides_t-{28*6}\"  # 4 weeks ago\n",
    "        ]\n",
    "\n",
    "        # Ensure the required columns exist in the test DataFrame\n",
    "    for col in last_4_weeks_columns:\n",
    "        if col not in X.columns:\n",
    "            raise ValueError(f\"Missing required column: {col}\")\n",
    "\n",
    "    # Calculate the average of the last 4 weeks\n",
    "    X[\"average_rides_last_4_weeks\"] = X[last_4_weeks_columns].mean(axis=1)\n",
    "\n",
    "    return X\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "add_feature_average_rides_last_4_weeks = FunctionTransformer(\n",
    "    average_rides_last_4_weeks, validate=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2cc54d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class TemporalFeatureEngineer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X_ = X.copy()\n",
    "        X_[\"hour_of_day\"] = X_[\"hour\"].dt.hour\n",
    "        X_[\"day_of_week\"] = X_[\"hour\"].dt.dayofweek\n",
    "\n",
    "        return X_.drop(columns=[\"hour\", \"start_station_id\"])\n",
    "\n",
    "add_temporal_features = TemporalFeatureEngineer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28467beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Downloading lightgbm-4.6.0-py3-none-macosx_12_0_arm64.whl.metadata (17 kB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /opt/anaconda3/envs/py313/lib/python3.13/site-packages (from lightgbm) (2.3.3)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/envs/py313/lib/python3.13/site-packages (from lightgbm) (1.16.2)\n",
      "Downloading lightgbm-4.6.0-py3-none-macosx_12_0_arm64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: lightgbm\n",
      "Successfully installed lightgbm-4.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c469b920",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    add_feature_average_rides_last_4_weeks,\n",
    "    add_temporal_features,\n",
    "    lgb.LGBMRegressor()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7213a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.8 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.8 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022193 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 40674\n",
      "[LightGBM] [Info] Number of data points in the train set: 196108, number of used features: 675\n",
      "[LightGBM] [Info] Start training from score 3.044792\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.8 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV] END lgbmregressor__bagging_fraction=0.8, lgbmregressor__bagging_freq=10, lgbmregressor__colsample_bytree=1.0, lgbmregressor__feature_fraction=0.6, lgbmregressor__learning_rate=0.1, lgbmregressor__max_depth=20, lgbmregressor__min_child_samples=50, lgbmregressor__n_estimators=1000, lgbmregressor__num_leaves=2, lgbmregressor__reg_alpha=0.5, lgbmregressor__reg_lambda=0.1, lgbmregressor__subsample=0.8; total time=  25.6s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.8 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.8 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021221 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 40541\n",
      "[LightGBM] [Info] Number of data points in the train set: 196109, number of used features: 675\n",
      "[LightGBM] [Info] Start training from score 2.950915\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.8 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV] END lgbmregressor__bagging_fraction=0.8, lgbmregressor__bagging_freq=10, lgbmregressor__colsample_bytree=1.0, lgbmregressor__feature_fraction=0.6, lgbmregressor__learning_rate=0.1, lgbmregressor__max_depth=20, lgbmregressor__min_child_samples=50, lgbmregressor__n_estimators=1000, lgbmregressor__num_leaves=2, lgbmregressor__reg_alpha=0.5, lgbmregressor__reg_lambda=0.1, lgbmregressor__subsample=0.8; total time=  26.0s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.8 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.8 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020147 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 34569\n",
      "[LightGBM] [Info] Number of data points in the train set: 196109, number of used features: 675\n",
      "[LightGBM] [Info] Start training from score 2.820814\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=0.8 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV] END lgbmregressor__bagging_fraction=0.8, lgbmregressor__bagging_freq=10, lgbmregressor__colsample_bytree=1.0, lgbmregressor__feature_fraction=0.6, lgbmregressor__learning_rate=0.1, lgbmregressor__max_depth=20, lgbmregressor__min_child_samples=50, lgbmregressor__n_estimators=1000, lgbmregressor__num_leaves=2, lgbmregressor__reg_alpha=0.5, lgbmregressor__reg_lambda=0.1, lgbmregressor__subsample=0.8; total time=  24.5s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026331 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 40674\n",
      "[LightGBM] [Info] Number of data points in the train set: 196108, number of used features: 675\n",
      "[LightGBM] [Info] Start training from score 3.044792\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV] END lgbmregressor__bagging_fraction=0.8, lgbmregressor__bagging_freq=10, lgbmregressor__colsample_bytree=1.0, lgbmregressor__feature_fraction=0.9, lgbmregressor__learning_rate=0.05, lgbmregressor__max_depth=-1, lgbmregressor__min_child_samples=20, lgbmregressor__n_estimators=200, lgbmregressor__num_leaves=256, lgbmregressor__reg_alpha=0.5, lgbmregressor__reg_lambda=0, lgbmregressor__subsample=1.0; total time=  21.0s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026817 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 40541\n",
      "[LightGBM] [Info] Number of data points in the train set: 196109, number of used features: 675\n",
      "[LightGBM] [Info] Start training from score 2.950915\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV] END lgbmregressor__bagging_fraction=0.8, lgbmregressor__bagging_freq=10, lgbmregressor__colsample_bytree=1.0, lgbmregressor__feature_fraction=0.9, lgbmregressor__learning_rate=0.05, lgbmregressor__max_depth=-1, lgbmregressor__min_child_samples=20, lgbmregressor__n_estimators=200, lgbmregressor__num_leaves=256, lgbmregressor__reg_alpha=0.5, lgbmregressor__reg_lambda=0, lgbmregressor__subsample=1.0; total time=  20.8s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026472 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 34569\n",
      "[LightGBM] [Info] Number of data points in the train set: 196109, number of used features: 675\n",
      "[LightGBM] [Info] Start training from score 2.820814\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[CV] END lgbmregressor__bagging_fraction=0.8, lgbmregressor__bagging_freq=10, lgbmregressor__colsample_bytree=1.0, lgbmregressor__feature_fraction=0.9, lgbmregressor__learning_rate=0.05, lgbmregressor__max_depth=-1, lgbmregressor__min_child_samples=20, lgbmregressor__n_estimators=200, lgbmregressor__num_leaves=256, lgbmregressor__reg_alpha=0.5, lgbmregressor__reg_lambda=0, lgbmregressor__subsample=1.0; total time=  19.8s\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=0.8 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=0.8 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020887 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 40674\n",
      "[LightGBM] [Info] Number of data points in the train set: 196108, number of used features: 675\n",
      "[LightGBM] [Info] Start training from score 3.044792\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=0.8 will be ignored. Current value: bagging_fraction=1.0\n",
      "[CV] END lgbmregressor__bagging_fraction=1.0, lgbmregressor__bagging_freq=5, lgbmregressor__colsample_bytree=1.0, lgbmregressor__feature_fraction=0.6, lgbmregressor__learning_rate=0.01, lgbmregressor__max_depth=10, lgbmregressor__min_child_samples=30, lgbmregressor__n_estimators=1000, lgbmregressor__num_leaves=2, lgbmregressor__reg_alpha=0, lgbmregressor__reg_lambda=0.5, lgbmregressor__subsample=0.8; total time=  25.2s\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=0.8 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=0.8 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019780 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 40541\n",
      "[LightGBM] [Info] Number of data points in the train set: 196109, number of used features: 675\n",
      "[LightGBM] [Info] Start training from score 2.950915\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=0.8 will be ignored. Current value: bagging_fraction=1.0\n",
      "[CV] END lgbmregressor__bagging_fraction=1.0, lgbmregressor__bagging_freq=5, lgbmregressor__colsample_bytree=1.0, lgbmregressor__feature_fraction=0.6, lgbmregressor__learning_rate=0.01, lgbmregressor__max_depth=10, lgbmregressor__min_child_samples=30, lgbmregressor__n_estimators=1000, lgbmregressor__num_leaves=2, lgbmregressor__reg_alpha=0, lgbmregressor__reg_lambda=0.5, lgbmregressor__subsample=0.8; total time=  24.3s\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=0.8 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=0.8 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019525 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 34569\n",
      "[LightGBM] [Info] Number of data points in the train set: 196109, number of used features: 675\n",
      "[LightGBM] [Info] Start training from score 2.820814\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=0.8 will be ignored. Current value: bagging_fraction=1.0\n",
      "[CV] END lgbmregressor__bagging_fraction=1.0, lgbmregressor__bagging_freq=5, lgbmregressor__colsample_bytree=1.0, lgbmregressor__feature_fraction=0.6, lgbmregressor__learning_rate=0.01, lgbmregressor__max_depth=10, lgbmregressor__min_child_samples=30, lgbmregressor__n_estimators=1000, lgbmregressor__num_leaves=2, lgbmregressor__reg_alpha=0, lgbmregressor__reg_lambda=0.5, lgbmregressor__subsample=0.8; total time=  25.4s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=0.8 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=0.8 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024527 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 40674\n",
      "[LightGBM] [Info] Number of data points in the train set: 196108, number of used features: 675\n",
      "[LightGBM] [Info] Start training from score 3.044792\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=0.8 will be ignored. Current value: bagging_fraction=0.7\n",
      "[CV] END lgbmregressor__bagging_fraction=0.7, lgbmregressor__bagging_freq=10, lgbmregressor__colsample_bytree=1.0, lgbmregressor__feature_fraction=0.8, lgbmregressor__learning_rate=0.1, lgbmregressor__max_depth=10, lgbmregressor__min_child_samples=10, lgbmregressor__n_estimators=1000, lgbmregressor__num_leaves=70, lgbmregressor__reg_alpha=0.5, lgbmregressor__reg_lambda=0.1, lgbmregressor__subsample=0.8; total time=  27.5s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=0.8 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=0.8 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023286 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 40541\n",
      "[LightGBM] [Info] Number of data points in the train set: 196109, number of used features: 675\n",
      "[LightGBM] [Info] Start training from score 2.950915\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=0.8 will be ignored. Current value: bagging_fraction=0.7\n",
      "[CV] END lgbmregressor__bagging_fraction=0.7, lgbmregressor__bagging_freq=10, lgbmregressor__colsample_bytree=1.0, lgbmregressor__feature_fraction=0.8, lgbmregressor__learning_rate=0.1, lgbmregressor__max_depth=10, lgbmregressor__min_child_samples=10, lgbmregressor__n_estimators=1000, lgbmregressor__num_leaves=70, lgbmregressor__reg_alpha=0.5, lgbmregressor__reg_lambda=0.1, lgbmregressor__subsample=0.8; total time=  26.9s\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=0.8 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=0.8 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024133 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 34569\n",
      "[LightGBM] [Info] Number of data points in the train set: 196109, number of used features: 675\n",
      "[LightGBM] [Info] Start training from score 2.820814\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=0.8 will be ignored. Current value: bagging_fraction=0.7\n",
      "[CV] END lgbmregressor__bagging_fraction=0.7, lgbmregressor__bagging_freq=10, lgbmregressor__colsample_bytree=1.0, lgbmregressor__feature_fraction=0.8, lgbmregressor__learning_rate=0.1, lgbmregressor__max_depth=10, lgbmregressor__min_child_samples=10, lgbmregressor__n_estimators=1000, lgbmregressor__num_leaves=70, lgbmregressor__reg_alpha=0.5, lgbmregressor__reg_lambda=0.1, lgbmregressor__subsample=0.8; total time=  27.2s\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.6 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.6 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018992 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 40674\n",
      "[LightGBM] [Info] Number of data points in the train set: 196108, number of used features: 675\n",
      "[LightGBM] [Info] Start training from score 3.044792\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.6 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[CV] END lgbmregressor__bagging_fraction=0.7, lgbmregressor__bagging_freq=1, lgbmregressor__colsample_bytree=0.6, lgbmregressor__feature_fraction=0.6, lgbmregressor__learning_rate=0.05, lgbmregressor__max_depth=30, lgbmregressor__min_child_samples=20, lgbmregressor__n_estimators=200, lgbmregressor__num_leaves=256, lgbmregressor__reg_alpha=1.0, lgbmregressor__reg_lambda=0.1, lgbmregressor__subsample=1.0; total time=  22.5s\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.6 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.6 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020719 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 40541\n",
      "[LightGBM] [Info] Number of data points in the train set: 196109, number of used features: 675\n",
      "[LightGBM] [Info] Start training from score 2.950915\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.6 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[CV] END lgbmregressor__bagging_fraction=0.7, lgbmregressor__bagging_freq=1, lgbmregressor__colsample_bytree=0.6, lgbmregressor__feature_fraction=0.6, lgbmregressor__learning_rate=0.05, lgbmregressor__max_depth=30, lgbmregressor__min_child_samples=20, lgbmregressor__n_estimators=200, lgbmregressor__num_leaves=256, lgbmregressor__reg_alpha=1.0, lgbmregressor__reg_lambda=0.1, lgbmregressor__subsample=1.0; total time=  22.9s\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.6 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.6 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020598 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 34569\n",
      "[LightGBM] [Info] Number of data points in the train set: 196109, number of used features: 675\n",
      "[LightGBM] [Info] Start training from score 2.820814\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.6 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[CV] END lgbmregressor__bagging_fraction=0.7, lgbmregressor__bagging_freq=1, lgbmregressor__colsample_bytree=0.6, lgbmregressor__feature_fraction=0.6, lgbmregressor__learning_rate=0.05, lgbmregressor__max_depth=30, lgbmregressor__min_child_samples=20, lgbmregressor__n_estimators=200, lgbmregressor__num_leaves=256, lgbmregressor__reg_alpha=1.0, lgbmregressor__reg_lambda=0.1, lgbmregressor__subsample=1.0; total time=  22.7s\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.6 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.6 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031236 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 38774\n",
      "[LightGBM] [Info] Number of data points in the train set: 294163, number of used features: 675\n",
      "[LightGBM] [Info] Start training from score 2.938840\n",
      "Best Parameters: {'lgbmregressor__subsample': 1.0, 'lgbmregressor__reg_lambda': 0.1, 'lgbmregressor__reg_alpha': 1.0, 'lgbmregressor__num_leaves': 256, 'lgbmregressor__n_estimators': 200, 'lgbmregressor__min_child_samples': 20, 'lgbmregressor__max_depth': 30, 'lgbmregressor__learning_rate': 0.05, 'lgbmregressor__feature_fraction': 0.6, 'lgbmregressor__colsample_bytree': 0.6, 'lgbmregressor__bagging_freq': 1, 'lgbmregressor__bagging_fraction': 0.7}\n",
      "Best Score (Negative MAE): -1.433819855854414\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.6 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "Test Set MAE: 2.0795584805042653\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Define the parameter grid for LGBMRegressor\n",
    "param_distributions = {\n",
    "    \"lgbmregressor__num_leaves\": [2, 50, 70, 256],\n",
    "    \"lgbmregressor__max_depth\": [-1, 10, 20, 30],\n",
    "    \"lgbmregressor__learning_rate\": [0.01, 0.05, 0.1, 0.2],\n",
    "    \"lgbmregressor__n_estimators\": [100, 200, 500, 1000],\n",
    "    \"lgbmregressor__min_child_samples\": [10, 20, 30, 50],\n",
    "    \"lgbmregressor__subsample\": [0.6, 0.8, 1.0],\n",
    "    \"lgbmregressor__colsample_bytree\": [0.6, 0.8, 1.0],\n",
    "    \"lgbmregressor__reg_alpha\": [0, 0.1, 0.5, 1.0],\n",
    "    \"lgbmregressor__reg_lambda\": [0, 0.1, 0.5, 1.0],\n",
    "    \"lgbmregressor__feature_fraction\": [0.6, 0.7, 0.8, 0.9, 1.0], \n",
    "    \"lgbmregressor__bagging_fraction\": [0.6, 0.7, 0.8, 0.9, 1.0], \n",
    "    \"lgbmregressor__bagging_freq\": [1, 5, 10],\n",
    "}\n",
    "\n",
    "# Initialize the RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=5,  # Number of parameter settings sampled\n",
    "    scoring=\"neg_mean_absolute_error\",  # Use MAE as the scoring metric\n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Fit the RandomizedSearchCV on the training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and the best score\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "print(\"Best Score (Negative MAE):\", random_search.best_score_)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = random_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"Test Set MAE:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb3e588",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
